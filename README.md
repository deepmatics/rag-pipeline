# RAG System Evaluation & Benchmark Report

**Environment:** MacBook Pro (48GB RAM) <br>
**Model:** Gemma 3 (Local via Hugging Face) <br>
**Dataset:** ArXiv Corpus (Vectara Open RAG Bench)

---

## ðŸ“Š Simple RAG
*Recorded on: 2026-01-06*

| Metric | Score | Interpretation |
| :--- | :--- | :--- |
| **Mean Precision** | `16%` | Only 1 in 6 retrieved chunks is relevant on average. |
| **Mean Recall** | `50%` | The correct document is missing 50% of the time. |
| **Overall F1** | `25%` | Low balance between accuracy and retrieval breadth. |
| **Mean Reciprocal Rank (MRR)** | `25%` | On average, the correct info is at the bottom of the Top 3. |


# Project Directory Structure

```text
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ chroma_db
â”œâ”€â”€ config
    â”œâ”€â”€ rag.yaml
â”œâ”€â”€ data
    â”œâ”€â”€ input
    â”œâ”€â”€ output
â”œâ”€â”€ docs
â”œâ”€â”€ experiments
â”œâ”€â”€ main.py
â”œâ”€â”€ rag_engine
    â”œâ”€â”€ app.py
    â”œâ”€â”€ chunking
        â”œâ”€â”€ recursive.py
    â”œâ”€â”€ data_loader
        â”œâ”€â”€ json_data.py
    â”œâ”€â”€ embeddings
        â”œâ”€â”€ langchain.py
    â”œâ”€â”€ eval.py
    â”œâ”€â”€ prompts
        â”œâ”€â”€ rag.yaml
    â”œâ”€â”€ utils
        â”œâ”€â”€ config_loader.py
    â”œâ”€â”€ vector_db
        â”œâ”€â”€ chroma.py